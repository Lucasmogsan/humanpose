{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import csv\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) - Test the pose algorithm\n",
    "Don't use if video already recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    # Loop through frames\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "            \n",
    "        if ret:\n",
    "            # Recolor image to RGB\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # mediapipe needs RGB\n",
    "            frame.flags.writeable = False\n",
    "            # Make detection\n",
    "            results = pose.process(frame)   # Store detections in result\n",
    "            # Recolor back to BGR\n",
    "            frame.flags.writeable = True\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                        mp_drawing.DrawingSpec(color=(245,177,66), thickness=2, circle_radius=2), # landmark drawing spec\n",
    "                                        mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)  # connection drawing spec\n",
    "                                        )\n",
    "            # Extract landmarks\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Get coordinates of joints\n",
    "            r_shoulder_xy = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            r_elbow_xy = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            r_wrist_xy = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            # Calculate angle between joints\n",
    "            # angle = get_angle(r_shoulder_xy, r_elbow_xy, r_wrist_xy)\n",
    "\n",
    "            cv2.imshow('Inference', frame)\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) - Record and save video\n",
    "Don't use if video already recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "data_folder = '../data/'\n",
    "video_name = 'tester.mp4'\n",
    "# create the full path to the video file\n",
    "video_path = os.path.join(data_folder, video_name)\n",
    "# make sure the folder exists - if not create it.\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "\n",
    "# create the video writer\n",
    "videoWriter = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc('P','I', 'M', '1'), fps, (int(width), int(height)))\n",
    "\n",
    "# start the webcam\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        videoWriter.write(frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        # press q to quit (and save video)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):   \n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# release the capture and video writer. Close windows.\n",
    "cap.release()\n",
    "videoWriter.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [4] - Capture Landmarks & Export to CSV\n",
    "Generating training data by annotating video\n",
    "\n",
    "From this we capture landmarks from a video and write it to a csv file by annotating up, transition, down state of a deadlift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name = 'coords.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['Class']\n",
    "# Add coordinates (x, y, z) for all landmarks and visibility flag (v)\n",
    "for val in range(1, 33+1):\n",
    "    landmarks += [f'x{val}', f'y{val}', f'z{val}', f'v{val}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmarks[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(csv_file_name, mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_landmark(result, action):\n",
    "    try:\n",
    "        keypoints = np.array([[res.x, res.y, res.z, res.visibility] for res in result.pose_landmarks.landmark]).flatten().tolist()  # Extract pose landmarks\n",
    "        keypoints.insert(0, action)  # Insert class number to list\n",
    "        # Export to CSV\n",
    "        with open(csv_file_name, mode='a', newline='') as f:\n",
    "            csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            csv_writer.writerow(keypoints)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('../data/tester.mp4')\n",
    "# Initiate holistic model\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Extract landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(color=(245, 177, 66), thickness=2, circle_radius=4),\n",
    "                                    mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                                    )\n",
    "        k = cv2.waitKey(1)\n",
    "        if k == 117:    # u - press 'u' when in upright state\n",
    "            export_landmark(results, 'up')\n",
    "        if k == 116:  # t - press 't' when in transition state\n",
    "            export_landmark(results, 'transition')\n",
    "        if k == 100:  # d - press 'd' when in down state\n",
    "            export_landmark(results, 'down')\n",
    "\n",
    "        # resize image\n",
    "        scale_percent = 50 # percent of original size\n",
    "        width = int(image.shape[1] * scale_percent / 100)\n",
    "        height = int(image.shape[0] * scale_percent / 100)\n",
    "        dim = (width, height)\n",
    "        resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        cv2.imshow('Raw webcam feed', resized)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [5] - Train custom model using Scikit Learn\n",
    "Based on the landmarks and annotation we just did we train and evaluate multiple classification models using Scikit Learn.\n",
    "Finally we use pickle to save the desired model for later use."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read collected data and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1) # Features\n",
    "y = df['Class'] # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train ML classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipielines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lms\\Anaconda3\\envs\\humanpose\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipielines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression())]),\n",
       " 'rc': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " 'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())])}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit_models['rf'].predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate and serialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr\n",
      "---\n",
      "Accuracy: 0.98\n",
      "Precision: 0.98\n",
      "Recall: 0.98\n",
      "\n",
      "rc\n",
      "---\n",
      "Accuracy: 0.99\n",
      "Precision: 0.99\n",
      "Recall: 0.99\n",
      "\n",
      "rf\n",
      "---\n",
      "Accuracy: 0.99\n",
      "Precision: 0.99\n",
      "Recall: 0.99\n",
      "\n",
      "gb\n",
      "---\n",
      "Accuracy: 0.99\n",
      "Precision: 0.99\n",
      "Recall: 0.99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print(algo)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy_score(y_test, yhat):.2f}')\n",
    "    print(f'Precision: {precision_score(y_test, yhat, average=\"micro\"):.2f}')\n",
    "    print(f'Recall: {recall_score(y_test, yhat, average=\"micro\"):.2f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model being tested:  rf\n",
      "--- Prediction ---\n",
      "['transition' 'transition' 'transition' 'down' 'up' 'down' 'up' 'down'\n",
      " 'up' 'up']\n",
      "--- True values ---\n",
      "172    transition\n",
      "466    transition\n",
      "196    transition\n",
      "416          down\n",
      "533            up\n",
      "210          down\n",
      "489            up\n",
      "236          down\n",
      "318            up\n",
      "162            up\n",
      "Name: Class, dtype: object\n"
     ]
    }
   ],
   "source": [
    "test_model = 'rf'\n",
    "yhat = fit_models[test_model].predict(X_test)\n",
    "\n",
    "print(\"Model being tested: \", test_model)\n",
    "print(\"--- Prediction ---\")\n",
    "print(yhat[:10])\n",
    "print(\"--- True values ---\")\n",
    "print(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir_name = '../models/deadlift_trainer_model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_dir_name, 'wb') as f:   # save / write model\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Make detections with model\n",
    "\n",
    "We load the desired model and use it to detect the classified stages in a deadlift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_dir_name, 'rb') as f:   # Load / read model (model_dir_name is the path to the model... the variable and used before in training the model but another can be used)\n",
    "    pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.DataFrame([row], columns=landmarks[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('../data/tester.mp4') # can also test with webcam: cap = cv2.VideoCapture(0)\n",
    "counter = 0\n",
    "current_state = ''\n",
    "# Initiate holistic model\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Extract landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(color=(245, 177, 66), thickness=2, circle_radius=4),\n",
    "                                    mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                                    )\n",
    "        try:\n",
    "            row = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten().tolist()  # Extract pose landmarks\n",
    "            X = pd.DataFrame([row], columns=landmarks[1:])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_prob = model.predict_proba(X)[0]\n",
    "            \n",
    "            if body_language_class == 'down' and body_language_prob[body_language_prob.argmax()] >= 0.7:\n",
    "                current_state = 'down'\n",
    "            # elif body_language_class == 'transition' and body_language_prob[body_language_prob.argmax()] >= 0.7:\n",
    "            #     current_state = 'transition'\n",
    "            elif current_state == 'down' and body_language_class == 'up' and body_language_prob[body_language_prob.argmax()] >= 0.7:\n",
    "                current_state = 'up'\n",
    "                counter += 1\n",
    "           # print(current_state)\n",
    "\n",
    "            # Get status box\n",
    "            cv2.rectangle(image, (0,0), (350, 60), (245, 117, 16), -1)\n",
    "\n",
    "            # Display Class\n",
    "            cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, body_language_class.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Display Probability\n",
    "            cv2.putText(image, 'PROB'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(body_language_prob[body_language_prob.argmax()],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Display conter\n",
    "            cv2.putText(image, 'COUNTER'\n",
    "                        , (260,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(counter)\n",
    "                        , (255,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "        # resize image\n",
    "        scale_percent = 50 # percent of original size\n",
    "        width = int(image.shape[1] * scale_percent / 100)\n",
    "        height = int(image.shape[0] * scale_percent / 100)\n",
    "        dim = (width, height)\n",
    "        resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        cv2.imshow('Camera / video feed', resized)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "humanpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
